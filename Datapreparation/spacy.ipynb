{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b346d71a",
   "metadata": {},
   "source": [
    "# Using spacy to remove stopwords, add lemma and entity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bebe53",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "Load dataset created in ../Datapreparation/Extract_street_terms_from_street_names.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all needed libraries\n",
    "import pandas as pd\n",
    "import spacy #Our NLP tools\n",
    "import de_core_news_md #!python -m spacy download de_core_news_md\n",
    "import fr_core_news_md #!python -m spacy download fr_core_news_md\n",
    "from IPython.display import Javascript\n",
    "from pandarallel import pandarallel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14462033",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames = pd.read_csv('streetnames.csv', encoding='UTF-8-SIG', sep=';')\n",
    "streetnames.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unused columns\n",
    "streetnames = streetnames.drop(['Unnamed: 0', 'COM_NAME', 'COM_CANTON','STR_EASTING', 'STR_NORTHING','COM_FOSNR',\n",
    "                        'STR_OFFICIAL','STR_TERMS', 'STR_PREPS', 'STN_LABEL_NO_BI', 'STN_LABEL_NO_TERMS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3187c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop nan\n",
    "missing_data = pd.DataFrame(\n",
    "    streetnames.isnull().sum(),\n",
    "    columns=['Missing Values'])\n",
    "\n",
    "print(missing_data)\n",
    "\n",
    "streetnames = streetnames.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b71d68",
   "metadata": {},
   "source": [
    "## Using spaCy Deutsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47313bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a German language model to do NLP - the models we use will influence our results a lot\n",
    "nlp = spacy.load('de_core_news_md') #Change fr/de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbe97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "#print(len(stopwords))\n",
    "#print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08707e",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames['SPACY_DE'] = streetnames['STN_LABEL_FINAL'].str.split(' ')\n",
    "\n",
    "streetnames['SPACY_DE'] = streetnames['SPACY_DE'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "\n",
    "streetnames['SPACY_DE'] = streetnames['SPACY_DE'].str.join(' ')\n",
    "\n",
    "#Delete spaces at the beginning and end of the string using function 'strip()'\n",
    "streetnames['SPACY_DE'] = streetnames['SPACY_DE'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f790417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create subset since spacy is slow for larger datasets\n",
    "streetnames100 = streetnames[:100].copy()\n",
    "\n",
    "#Make ist faster\n",
    "pandarallel.initialize()\n",
    "#pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b8a199",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92d2fd-a025-40f3-989d-0bf018e19c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForLemma(num):\n",
    "    doc = nlp(num)\n",
    "    #print(len(doc))\n",
    "    if len(doc)>0:\n",
    "        return doc[0].lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d8804-a441-48b5-80a3-282b2909b64d",
   "metadata": {},
   "source": [
    "⚠ Attention: This following code may take a while (>5min..)  \n",
    "Use `parallel_apply` from `pandarallel` to run query in parallel. This needs more CPU but is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae0173-bbf1-434d-97b7-6e9a05f87a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import datetime\n",
    "#pandarallel.initialize(progress_bar=True)\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "temp = streetnames[\"SPACY_DE\"].parallel_apply(checkForLemma)\n",
    "#temp = streetnames[\"SPACY_DE\"].apply(checkForLemma)\n",
    "\n",
    "print (\"Duration: \", datetime.datetime.now()-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a190f-09df-4f10-b914-e996f97570dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp.rename(\"SPACY_DE_LEMMA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363b67d-9bbc-4105-9868-aae2a7434d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames = pd.concat((streetnames,temp2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b1374-7ef7-4f51-a5fa-2e629215ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079e96b",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "Labelling named “real-world” objects, like persons, companies or locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bef1a-2994-4681-a4f7-830ad5bd7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForEntity(num):\n",
    "    doc = nlp(num)\n",
    "    #print(len(doc))\n",
    "    if doc.ents:\n",
    "        #print(num, \"ENT\")\n",
    "        for ent in doc.ents:\n",
    "            if len(num) == ent.end_char: #will be not equal if nlp did not recoginse a two word term as one entity. e.g.: General Guisan\n",
    "                return ent.label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a49cc-b6e0-416c-bbb6-3cd5ef81d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "temp = streetnames[\"SPACY_DE\"].parallel_apply(checkForEntity)\n",
    "#temp = streetnames[\"SPACY_DE\"].apply(checkForEntity)\n",
    "\n",
    "print (\"Duration: \", datetime.datetime.now()-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22650877-b829-4ec9-bb0c-38cf85da17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp.rename(\"SPACY_DE_ENTITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249a3ac-1401-444d-a398-e75181934563",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames = pd.concat((streetnames,temp2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610fc79-cf48-4ed9-8ae3-6e144544f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da872d6",
   "metadata": {},
   "source": [
    "## Using spaCy Français"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a German language model to do NLP - the models we use will influence our results a lot\n",
    "nlp = spacy.load('fr_core_news_md') #Change fr/de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "#print(len(stopwords))\n",
    "#print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d8954",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames['SPACY_FR'] = streetnames['STN_LABEL_FINAL'].str.split(' ')\n",
    "\n",
    "streetnames['SPACY_FR'] = streetnames['SPACY_FR'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "\n",
    "streetnames['SPACY_FR'] = streetnames['SPACY_FR'].str.join(' ')\n",
    "\n",
    "#Delete spaces at the beginning and end of the string using function 'strip()'\n",
    "streetnames['SPACY_FR'] = streetnames['SPACY_FR'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8af20a",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7771b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in streetnames100.SPACY_FR.items():\n",
    "for i in streetnames.SPACY_FR.items():\n",
    "    doc = nlp(i[1])\n",
    "    for token in doc:\n",
    "        #print(f\"{token.text:<20}\\t{token.lemma_:<20}\\t{token.pos_:<6}\\t{token.is_stop}\")\n",
    "        #streetnames100.loc[i[0], 'SPACY_DE_LEMMA'] = token.lemma_\n",
    "        streetnames.loc[i[0], 'SPACY_FR_LEMMA'] = token.lemma_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a97d7",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "Labelling named “real-world” objects, like persons, companies or locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in streetnames100.SPACY_FR.items():\n",
    "for i in streetnames.SPACY_FR.items():\n",
    "    doc = nlp(i[1])\n",
    "    #print(i[0])\n",
    "    for ent in doc.ents:\n",
    "        #print(f\"{ent.text:<20}\\t{ent.label_:<3}\")\n",
    "        #streetnames100.loc[i[0], 'SPACY_DE_ENT'] = ent.label_\n",
    "        streetnames.loc[i[0], 'SPACY_FR_ENT'] = ent.label_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b2c23",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc19de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = streetnames.groupby(\"SPACY_FR_ENT\").count()\n",
    "most_common.STR_ESID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = streetnames.groupby(\"SPACY_DE_ENT\").count()\n",
    "most_common.STR_ESID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207aae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "streetnames.to_csv('spacy-out.csv', encoding='UTF-8-SIG', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
